# FreqMedCLIP Code Location Map

## ğŸ“ Core Components

### 1. **Frequency & Fusion Modules**
```
ğŸ“‚ scripts/freq_components.py
   â”œâ”€â”€ DWTForward                    # Wavelet transform (Haar filters)
   â”‚   â”œâ”€â”€ __init__()               # Initialize 4 Haar kernels (LL, LH, HL, HH)
   â”‚   â””â”€â”€ forward()                # Split image â†’ HF features (LH, HL, HH)
   â”‚
   â””â”€â”€ SmartFusionBlock              # Coarse-to-Fine fusion
       â”œâ”€â”€ __init__()               # Conv adapters + GroupNorm
       â””â”€â”€ forward()                # Gating + Residual fusion
```

**Key Files:**
- `scripts/freq_components.py` â€” DWT + SmartFusionBlock
- `reference_wavelet.py` â€” Reference implementation
- `reference_fusion.py` â€” Reference implementation

---

### 2. **Training Pipeline**
```
ğŸ“‚ train_freq_fusion.py
   â”œâ”€â”€ FreqMedCLIPDataset           # Load images/masks/prompts
   â”‚   â”œâ”€â”€ __init__()              # Setup data paths
   â”‚   â”œâ”€â”€ __len__()               # Dataset size
   â”‚   â””â”€â”€ __getitem__()           # Load 1 sample
   â”‚
   â”œâ”€â”€ FrequencyMedCLIPSAMv2        # Model wrapper
   â”‚   â”œâ”€â”€ __init__()              # Wrap BiomedCLIP + DWT + Fusion
   â”‚   â””â”€â”€ forward()               # Full forward pass
   â”‚
   â”œâ”€â”€ DiceLoss                     # Loss function
   â”‚   â””â”€â”€ forward()               # Dice coefficient
   â”‚
   â””â”€â”€ main()                       # Training loop
       â”œâ”€â”€ Load data               # DataLoader
       â”œâ”€â”€ Initialize model        # BiomedCLIP + components
       â”œâ”€â”€ Training loop           # Backprop + optimize
       â””â”€â”€ Save checkpoints        # Every 10 epochs
```

**Helper Scripts:**
- `run_train_phase2.ps1` â€” PowerShell wrapper
- `train_and_eval.bat` â€” Train + evaluate

---

### 3. **Postprocessing (THÃŠM Má»šI)**
```
ğŸ“‚ scripts/postprocess.py
   â”œâ”€â”€ postprocess_saliency_kmeans()     # KMeans clustering (default)
   â”‚   â”œâ”€â”€ Resize to 256x256            # Speed up
   â”‚   â”œâ”€â”€ KMeans(n_clusters=2)         # Foreground/Background
   â”‚   â”œâ”€â”€ Identify foreground          # Higher centroid
   â”‚   â”œâ”€â”€ Resize back                  # Original size
   â”‚   â””â”€â”€ Filter top-K components      # Keep largest
   â”‚
   â””â”€â”€ postprocess_saliency_threshold()  # Simple thresholding
       â”œâ”€â”€ Apply threshold              # Fixed value
       â””â”€â”€ Filter top-K components      # Keep largest
```

**Batch Processing Scripts:**
- `save_freqmedclip_predictions.py` â€” Generate raw saliency maps
- `postprocess_freqmedclip_outputs.py` â€” Batch postprocess
- `run_freqmedclip_pipeline.ps1` â€” Complete pipeline

**Visualization:**
- `visualize_prediction.py` â€” Before/after comparison (3x3 grid)

---

### 4. **Evaluation**
```
ğŸ“‚ evaluation/
   â”œâ”€â”€ eval.py                      # Compute Dice/IoU
   â””â”€â”€ SurfaceDice.py              # Surface Dice (NSD)
```

**Comparison Scripts:**
- `compare_epochs.py` â€” Compare different checkpoints
- `create_overlays.py` â€” Create overlay visualizations

---

### 5. **Text Prompts**
```
ğŸ“‚ saliency_maps/text_prompts.py
   â”œâ”€â”€ breast_tumor_P2_prompts     # 20 prompts for breast tumors
   â”œâ”€â”€ brain_tumor_prompts         # Brain tumor prompts
   â”œâ”€â”€ lung_CT_prompts            # Lung CT prompts
   â””â”€â”€ lung_Xray_prompts          # Lung X-ray prompts

ğŸ“‚ saliency_maps/text_prompts/
   â”œâ”€â”€ breast_tumors_testing.json  # JSON mapping: {filename: prompt}
   â”œâ”€â”€ brain_tumors_testing.json
   â”œâ”€â”€ lung_CT_testing.json
   â””â”€â”€ lung_Xray_testing.json
```

**Create Prompts:**
- `scripts/create_prompts.py` â€” Generate JSON prompt files

---

### 6. **BiomedCLIP Wrapper**
```
ğŸ“‚ scripts/biomedclip_wrapper.py   # For BiomedCLIP (timm-free)
ğŸ“‚ scripts/clip_wrapper.py         # For OpenAI CLIP (legacy)
ğŸ“‚ scripts/methods.py              # M2IB/IBA methods
   â”œâ”€â”€ vision_heatmap_iba()        # Vision saliency map
   â”œâ”€â”€ text_heatmap_iba()          # Text saliency map
   â””â”€â”€ vision_heatmap_freq_aware() # Frequency-aware (NEW)
```

---

### 7. **SAM Integration**
```
ğŸ“‚ segment-anything/
   â”œâ”€â”€ prompt_sam.py               # SAM refinement script
   â””â”€â”€ sam_checkpoints/
       â””â”€â”€ sam_vit_h_4b8939.pth    # SAM-ViT-H checkpoint
```

---

## ğŸ”„ Pipeline Flow

### **Phase 2 Training (Current)**
```
Input Image (224x224)
    â†“
[BiomedCLIP Vision Encoder]
    â”œâ”€â”€ Deep Layers (7-11) â†’ LF Features (semantic) â†’ Coarse Map (M2IB)
    â””â”€â”€ Shallow Layers (3-4) â†’ HF base
    â†“
[DWT Forward] (scripts/freq_components.py)
    â†“ Input: pixel_values (B,3,224,224)
    â†“ Output: HF_wavelet (B,9,112,112)
    â†“
[Concatenate] shallow_HF + DWT_HF â†’ hf_features (B,777,112,112)
    â†“
[SmartFusionBlock] (scripts/freq_components.py)
    â†“ Input: hf_features + coarse_map
    â†“ Output: fine_map (B,1,112,112)
    â†“
[Loss] BCE + Dice with GT masks
    â†“
[Optimizer] AdamW (lr=1e-4)
    â†“
Checkpoints saved every 10 epochs
```

### **Inference Pipeline (NEW with Postprocessing)**
```
Input Image
    â†“
[Trained FreqMedCLIP] (train_freq_fusion.py)
    â†“ Output: fine_map (B,1,224,224)
    â†“
[Upsample + Sigmoid]
    â†“ Output: raw_saliency (224,224) [0-1]
    â†“
[POSTPROCESSING] (scripts/postprocess.py)  â† THÃŠM Má»šI
    â”œâ”€â”€ KMeans clustering (default)
    â”œâ”€â”€ Connected components filtering
    â””â”€â”€ Keep top-K largest
    â†“ Output: cleaned_mask (224,224) {0,255}
    â†“
[SAM Refinement] (segment-anything/prompt_sam.py)
    â”œâ”€â”€ Extract bounding box from cleaned_mask
    â”œâ”€â”€ SAM inference with box prompt
    â””â”€â”€ Output: final_mask (original size)
    â†“
Final Segmentation
```

---

## ğŸ“‚ File Organization

```
MedCLIP-SAMv2/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ freq_components.py              âœ… DWT + SmartFusionBlock
â”‚   â”œâ”€â”€ postprocess.py                  âœ… KMeans + Threshold (NEW)
â”‚   â”œâ”€â”€ biomedclip_wrapper.py           âœ… BiomedCLIP encoder wrapper
â”‚   â”œâ”€â”€ methods.py                      âœ… M2IB/IBA methods
â”‚   â”œâ”€â”€ utils.py                        âœ… Helper functions
â”‚   â”œâ”€â”€ plot.py                         âœ… Visualization utils
â”‚   â””â”€â”€ create_prompts.py               âœ… Generate prompt JSONs
â”‚
â”œâ”€â”€ saliency_maps/
â”‚   â”œâ”€â”€ text_prompts.py                 âœ… Python prompt lists
â”‚   â”œâ”€â”€ text_prompts/                   âœ… JSON prompt files
â”‚   â””â”€â”€ model/                          âœ… BiomedCLIP config
â”‚
â”œâ”€â”€ train_freq_fusion.py                âœ… Phase 2 training script
â”œâ”€â”€ save_freqmedclip_predictions.py     âœ… Batch generate predictions (NEW)
â”œâ”€â”€ postprocess_freqmedclip_outputs.py  âœ… Batch postprocessing (NEW)
â”œâ”€â”€ visualize_prediction.py             âœ… Before/after visualization (UPDATED)
â”œâ”€â”€ run_freqmedclip_pipeline.ps1        âœ… Complete pipeline (NEW)
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ eval.py                         âœ… Dice/IoU evaluation
â”‚   â””â”€â”€ SurfaceDice.py                  âœ… NSD metric
â”‚
â”œâ”€â”€ segment-anything/
â”‚   â”œâ”€â”€ prompt_sam.py                   âœ… SAM refinement
â”‚   â””â”€â”€ sam_checkpoints/                âœ… SAM weights
â”‚
â”œâ”€â”€ checkpoints/                        ğŸ“ Saved fusion weights
â”‚   â””â”€â”€ breast_tumors/
â”‚       â””â”€â”€ fusion_breast_tumors_epoch100.pth
â”‚
â”œâ”€â”€ predictions/                        ğŸ“ Inference outputs (NEW)
â”‚   â”œâ”€â”€ breast_tumors_raw/              â†’ Raw saliency maps
â”‚   â””â”€â”€ breast_tumors_cleaned/          â†’ Cleaned masks (USE THIS)
â”‚
â”œâ”€â”€ visualizations/                     ğŸ“ Visual comparisons
â”‚   â””â”€â”€ breast_tumors/
â”‚       â””â”€â”€ visual_*.png                â†’ 3x3 grid comparisons
â”‚
â”œâ”€â”€ data/                               ğŸ“ Datasets
â”‚   â”œâ”€â”€ breast_tumors/
â”‚   â”‚   â”œâ”€â”€ train_images/
â”‚   â”‚   â”œâ”€â”€ train_masks/
â”‚   â”‚   â”œâ”€â”€ val_images/
â”‚   â”‚   â”œâ”€â”€ val_masks/
â”‚   â”‚   â”œâ”€â”€ test_images/
â”‚   â”‚   â””â”€â”€ test_masks/
â”‚   â”œâ”€â”€ brain_tumors/
â”‚   â”œâ”€â”€ lung_CT/
â”‚   â””â”€â”€ lung_Xray/
â”‚
â””â”€â”€ Documentation/
    â”œâ”€â”€ PIPELINE_-FreqMedCLIP-Smart-Single-Stream.md  âœ… Architecture overview
    â”œâ”€â”€ FreqMedCLIP_Implementation_Guide.md           âœ… Detailed guide
    â”œâ”€â”€ Pipeline.md                                   âœ… Detailed pipeline
    â”œâ”€â”€ POSTPROCESSING_GUIDE.md                       âœ… Postprocessing guide (NEW)
    â””â”€â”€ IMPLEMENTATION_SUMMARY.md                     âœ… TGCAM variant
```

---

## ğŸ¯ Quick Reference

### **Train FreqMedCLIP**
```powershell
.\run_train_phase2.ps1 -Dataset breast_tumors -Epochs 100
```

### **Generate Predictions + Postprocess**
```powershell
.\run_freqmedclip_pipeline.ps1 `
    -Dataset breast_tumors `
    -Checkpoint checkpoints/breast_tumors/fusion_breast_tumors_epoch100.pth
```

### **Evaluate Results**
```bash
python evaluation/eval.py \
    --pred-dir predictions/breast_tumors_cleaned \
    --gt-dir data/breast_tumors/test_masks
```

### **Visualize Sample**
```bash
python visualize_prediction.py
```

---

## ğŸ†• What's New (Postprocessing Integration)

1. **`scripts/postprocess.py`**
   - `postprocess_saliency_kmeans()` â€” KMeans clustering
   - `postprocess_saliency_threshold()` â€” Simple thresholding

2. **`save_freqmedclip_predictions.py`**
   - Batch generate raw saliency maps

3. **`postprocess_freqmedclip_outputs.py`**
   - Batch postprocess predictions
   - Support KMeans and threshold methods

4. **`visualize_prediction.py` (UPDATED)**
   - Show before/after postprocessing
   - 3x3 grid with overlays

5. **`run_freqmedclip_pipeline.ps1`**
   - Complete pipeline: predict â†’ postprocess â†’ visualize

6. **`POSTPROCESSING_GUIDE.md`**
   - Comprehensive postprocessing documentation

---

## ğŸ“š Documentation Files

- **`PIPELINE_-FreqMedCLIP-Smart-Single-Stream.md`** â€” High-level architecture
- **`FreqMedCLIP_Implementation_Guide.md`** â€” Detailed implementation
- **`Pipeline.md`** â€” Step-by-step pipeline (99 lines)
- **`POSTPROCESSING_GUIDE.md`** â€” Postprocessing methods & usage (NEW)
- **`IMPLEMENTATION_SUMMARY.md`** â€” TGCAM variant summary

---

**Last Updated:** December 1, 2025  
**Status:** Production-ready with postprocessing  
**Next Phase:** SAM integration + Phase 3 (weakly-supervised nnU-Net)
